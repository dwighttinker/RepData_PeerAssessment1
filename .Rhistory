getwd()
mylist <- list(rep(1,4), rep(2,3), rep(3,2), rep(4,1))
mylist
mylist2 <- rep(1:4m 4:1)
mylist2 <- rep(1:4,4:1)
mylist2
split(mylist2)
mean(x)
traceback()
lm(y ~ x)
traceback()
debug(lm)
lm(y ~ x)
x <- rnorm(10)
print(x)
x <- rnorm(10,20,2)
print(x)
summary(x)
set.seed(1)
rnorm(5)
rnorm(5)
rpois(10,1)
rpois(10,2)
rpois(10,20)
ppois(2,2)
set.seed(20)
x <- rnorm(100)
e <- rnorm(100,0,2)
y <- 0.5 + 2 * x + e
summary(y)
plot(x,y)
x <- (1:100)
e <- rnorm(100,0,1)
y <- 1.5 - 3 * x + e
plot(x,y)
set.seed(10)
x <- rbinom(100,1,0.5)
e <- rnorm(100,0,2)
summary(y)
y <- 0.5 + 2 * x + e
summay(y)
aummary(y)
summary(y)
plot(x,y)
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3 * x
y <- rpois(100, exp(log.mu))
summary(y)
plot(x,y)
da <- source("http://spark-public.s3.amazonaws.com/compdata/scripts/corr-test.R")
da
source("http://spark-public.s3.amazonaws.com/compdata/scripts/corr-test.R")
corr.testscript()
library(lattice)
data(environmental)
xyplot(ozone ~ radiation, data = environmental)
xyplot(ozone ~ radiation, data = environmental, main = "Ozone vs. Radiation")
xyplot(ozone ~ temperature, data = environmental)
temp.cut <- equal.count(environmental$temperature, 4)
temp.cut
xyplot(ozone ~ radiation | temp.cut, data = environmental)
xyplot(ozone ~ radiation | temp.cut, data = environmental, layout = c(1,4))
install.packages("knitr")
install.packages("ggplot2")
install.packages("xtable")
cars <- c(2,4,5,6,4,3,7)
plot(cars)
histogram(cars)
splom(cars)
xyplot(cars)
coplot(cars)
?coplot
?mtext
?lattice
??lattice
set.seed(31)
heightsCM <- rnorm(30,mean=188,sd=5)
weightsK <- rnorm(30,mean=84,sd=3)
hasDaughter <- sample(c(TRUE,FALSE),size=30,replace=T)
dataFrame <- data.frame(heightsCM,weightsK,hasDaughter)
dataFrame
dataFrame[dataframe$heightsCM>188]
df2 <- dataFrame[dataFrame$heightsCM>188]
df2 <- dataFrame[heightsCM>188]
dataFrame(heightsCM>188)
df2 <- dataFrame[heightsCM>188,]
summary(df2)
mean(df2$weightsK)
set.seed(41)
cauchyValues <- rnorm(100)
set.seed(415)
result <- sample(cauchyValues,size=10,replace=TRUE)
result
rcauchy
?rcauchy
set.seed(41)
cauchyValues <- rcauchy(100)
set.seed(415)
result <- sample(cauchyValues,size=10,replace=TRUE)
result
find.packages("devtools")
install.package("devtools")
install.packages("devtools")
install.packages("KernSmooth")
load("KernSmooth")
load.package("KernSmooth")
load.packages("KernSmooth")
load("KernSmooth")
library("KernSmooth")
library(UsingR)
install.packages("UsingR")
library(UsingR)
data(galton)
par(mfrow=c(1,2))
hist(galton$child,col="blue",breaks=100)
hist(galton$parent,col="blue",breaks=100)
install.packages("kernlab")
library(kernlab)
data(spam)
install.packages("manipulate")
install.packages("manipulate")
install.packages("rcharts")
install.packages("devtools")
require(devtools)
install_github('rCharts', 'ramnathv')
install.packages("slidify")
install_github("slidify", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
install_github('ramnathv/rCharts@dev')
install_github('ramnathv/rMaps')
install_github('rNotebook', 'ramnathv')
install_github('rNVD3', 'ramnathv')
require(rNVD3)
bar1 <- nvd3Plot(~gear, data = mtcars, type = "discreteBarChart", width = 600)
bar1$printChart("chart1")
library(mtcars)
data
mtcars
require(rNVD3)
bar1 <- nvd3Plot(~gear, data = mtcars, type = "discreteBarChart", width = 600)
bar1$printChart("chart1")
install.packages("rjson")
install.packages("rjson")
install.packages("rjson")
library(UsingR)
library(manipulate)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
mean(w*(x - mu)^2)
data(mtcars)
rho <- cor(x,y)
rho <- cor(x,w)
myPlot <- function(x,w){}
myPlot <- function(x,w){
plot(x,w,
frsme=false)
}
myPlot <- function(x,w){
plot(x,w,
frame=false)
}
myPlot(x,w)
myPlot <- function(x,w){
plot(x,w,
frame=FALSE)
}
myPlot(x,w)
abline(0,1)
abline(0,rho, lwd=2)
abline(0,1/rho, lwd=2)
abline(h=0); abline(v=0)
beta1 <- cor(w,x) * sd(w) / sd(x)
beta0 <- mean(y) - beta1 * mean(x)
rbind(c(beta0m beta1), coef(lm(w~x)))
beta1 <- cor(w,x) * sd(w) / sd(x)
beta0 <- mean(w) - beta1 * mean(x)
rbind(c(beta0, beta1), coef(lm(w~x)))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
instal.packages("AppliedPredictiveModeling")
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
data(concrete)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(concrete)
library(Hmisc )
?cut2
plot(CompressiveStrength, concrete)
plot(concrete$CompressiveStrength)
plot(concrete$CompressiveStrength, col = xcols)
xcols = cut2(concrete)
xcols = cut2(concrete)
xcols = cut2(testing)
xcols = cut2(testing$CompressiveStrength)
plot(testing$CompressiveStrength, col = xcols)
xcols = cut2(training$CompressiveStrength)
plot(training$CompressiveStrength, col = xcols)
legend()
legend( legend=xcols)
legend( legend=training$CompressiveStrength)
legend('topright', legend=training$CompressiveStrength)
plot(training$CompressiveStrength, col = xcols)
legend('topright', xcols)
plot(training$CompressiveStrength, col = xcols)
legend('topright', training$CompressiveStrength, col = xcols)
legend('topright', training$CompressiveStrength, col = xcols)
plot(training$CompressiveStrength, col = xcols)
legend('topright', training$CompressiveStrength, col = training$CompressiveStrength)
legend('topright', training$CompressiveStrength)
legend('topright', legend=training$CompressiveStrength)
plot(training$CompressiveStrength, col = xcols)
legend('topright', legend=xcols)
plot(training$CompressiveStrength, col = xcols)
legend('topright', lty=1, legend=xcols, bty='n', cex=.75)
plot(training$CompressiveStrength, col = xcols)
legend('topright', lty=1, legend=xcols, col = xcols, bty='n', cex=.75)
xcols
xcols = cut2(training$CompressiveStrength, g=10)
plot(training$CompressiveStrength, col = xcols)
legend('topright', lty=1, legend=xcols, col = xcols, bty='n', cex=.75)
xcols = cut2(training$Age)
plot(training$CompressiveStrength, col = xcols)
xcols = cut2(training$FlyAsh)
plot(training$CompressiveStrength, col = xcols)
legend('topright', lty=1, legend=xcols, col = xcols, bty='n', cex=.75)
xcols = cut2(training$Cement)
plot(training$CompressiveStrength, col = xcols)
legend('topright', lty=1, legend=xcols, col = xcols, bty='n', cex=.75)
xcols = cut2(training$BlastFunaceSlag)
xcols = cut2(training$Water)
plot(training$CompressiveStrength, col = xcols)
xcols = cut2(training$SuperPlasticizer)
xcols = cut2(training$SuperPlasticizer)
xcols = cut2(training$Superplasticizer)
plot(training$CompressiveStrength, col = xcols)
xcols = cut2(training$CourseAggregate)
xcols = cut2(training$CoarseAggregate)
plot(training$CompressiveStrength, col = xcols)
legend('topright', lty=1, legend=xcols, col = xcols, bty='n', cex=.75)
xcols = cut2(training$FineAggregate)
plot(training$CompressiveStrength, col = xcols)
xcols = cut2(training$CompressiveStrength)
plot(training$CompressiveStrength, col = xcols)
xcols = cut2(training$FlyAsh)
plot(training$CompressiveStrength, col = xcols)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$SuperPlasticizer)
hist(training)
hist(log(training$SuperPlasticizer)
)
head(training$Superplasticizer)
head(training$Superplasticizer, rnum=100)
training$Superplasticizer
log(training$Superplasticizer)
log(training$Superplasticizer+1)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training
trainingIl <- training[^Il,]
trainingIl <- training["^Il",]
trainingIl
trainingIl <- training[,"^Il"]
trainingIl <- training["^Il",]
trainingIl <- training[grep("^Il", names(training))]
trainingIl
trainingIl <- training[grep("^IL", names(training))]
trainingIl
library(AppliedPredictiveModeling)
library(caret)
library(Hmisc)
data(AlzheimerDisease)
data(concrete)
set.seed(3433)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIl <- training[grep("^IL", names(training))]
preProc <- preProcess(trainingIl, method="pca", pcaComp=2)
preProc <- preProcess(trainingIl, method="pca", pcaComp=4)
newProc <- predict(preProc, trainingIl)
trainPC <- predict(preProc, trainingIl)
modelFit <- train(trainingIl, method="glm", data=trainPC)
trainPC <- predict(preProc, trainingIl, outcome=hh)
hh
trainCorr <- cor(trainingIl)
highCorr <- findCorrelation(trainCorr, 0.90)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIl <- training[grep("^IL", names(training))]
trainCorr <- abs(cor(trainingIl))
diag(M) <- 0
diag(trainCorr) <- 0
hist(trainingIl)
preProc <- preProcess(trainingIl, method="pca", pcaComp=2)
newProc <- predict(preProc, trainingIl)
hist(newProc)
trainPC <- predict(preProc, trainingIl)
summary(trainPC)
AlzheimerDisease
data(AlzheimerDisease)
adData
names(adData)
diagnosis
?diagnosis
highCorr <- findCorrelation(trainCorr, 0.90)
View(predictors)
View(trainCorr)
View(training)
trainPC <- predict(preProc, trainingIl)
modelFit <- train(trainingIl ~ training$diagnosis, method="glm", data=trainPC)
highCorr <- findCorrelation(trainCorr, 0.50)
highCorr <- findCorrelation(trainCorr, 0.60)
highCorr <- findCorrelation(trainCorr, 0.70)
highCorr <- findCorrelation(trainCorr, 0.80)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[grep("^IL|Diagnosis", names(training))]
View(trainingIL)
trainingIL <- training[grep("^IL|diagnosis", names(training))]
View(trainingIL)
preProc <- preProcess(trainingIL, method="pca", pcaComp=12)
preProc <- preProcess(trainingIL[,-1], method="pca", pcaComp=12)
preProc <- preProcess(trainingIL[,-1], method="pca", pcaComp=2)
preProc <- preProcess(trainingIL[,-1], method="pca", pcaComp=12)
newProc <- predict(preProc, trainingIL[,-1])
hist(trainingIL)
plot(trainingIL ~ trainingIl[,1])
plot(trainingIL ~ trainingIL[,1])
hist(newProc)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
train = createDataPartition(diagnosis, p = 0.50,list=FALSE)
test = createDataPartition(diagnosis, p = 0.50,list=FALSE)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
---
)
?yaml
?YAML
?slidify
library(devtools)
library(slidify)
setwd("E:/Dwight/Data Libraries/Education/coursera/reproducable-research/project 1/grading/4")
setwd("E:/Dwight/Data Libraries/Education/coursera/reproducable-research/project 1/RepData_PeerAssessment1")
library(ggplot2)
library(scales)
library(sqldf)
data <- read.csv("./raw-data/activity.csv")
dailySums <- aggregate( steps~date, data=data, FUN=sum, na.rm=TRUE)
dailyMeans <- aggregate( steps~interval, data=data, FUN=mean, na.rm=TRUE)
ggplot(data, aes(x=factor(date), y=steps)) + stat_summary(fun.y="sum", geom="histogram", na.rm=TRUE) + theme(axis.text.x = element_text(angle = 90, vjust = .5, hjust = 1)) + xlab("Date") + ylab("Total steps") + ggtitle("Daily Steps")
ggplot(data=dailySums, aes(x=steps)) + geom_histogram(binwidth = diff(range(dailySums$steps))/14, fill="#FFFFFF", colour="black") + xlab("Steps") + ylab("Frequency") + ggtitle("Mean Steps Taken per Day")
meanSteps <- round( mean( dailySums$steps, na.rm = TRUE ), 1 )
medianSteps <- round( median( dailySums$steps, na.rm = TRUE ), 1 )
ggplot(dailyMeans, aes(interval, steps)) + geom_line() + xlab("Interval") + ylab("Steps") + ggtitle("Average Daily Activity")
mostActiveInterval <- dailyMeans[which.max(dailyMeans$steps),]
naCount <- length(which(is.na(data$steps)))
dataComplete <- data[complete.cases(data),]
dailySumsComplete <- aggregate( steps~date, data=dataComplete, FUN=sum, na.rm=FALSE)
dailyMeansComplete <- aggregate( steps~interval, data=dataComplete, FUN=mean, na.rm=FALSE)
meanStepsComplete <- round( mean( dailySumsComplete$steps, na.rm = FALSE ), 1 )
medianStepsComplete <- round( median( dailySumsComplete$steps, na.rm = FALSE ), 1 )
ggplot(data=dailySumsComplete, aes(x=steps)) + geom_histogram(binwidth = diff(range(dailySumsComplete$steps))/14, fill="#FFFFFF", colour="black") + xlab("Steps") + ylab("Frequency") + ggtitle("Mean Steps Taken per Day")
partOfWeek <- weekdays(as.Date(data$date)) == "Sunday" | weekdays(as.Date(data$date)) == "Saturday"
partOfWeek <- ifelse(partOfWeek==TRUE, "Weekend", "Weekday")
partOfWeek <- as.factor(partOfWeek)
dailyMeansComplete <- merge(dailyMeansComplete, partOfWeek)
View(dataComplete)
e
dataComplete <- data[complete.cases(data),]
View(dataComplete)
data <- read.csv(unz(temp, "activity.csv"))
dataComplete <- data[complete.cases(data),]
data <- read.csv("./raw-data/activity.csv")
dataComplete <- data[complete.cases(data),]
View(dataComplete)
append(dailyMeansComplete, partOfWeek)
View(dataComplete)
partOfWeek <- weekdays(as.Date(data$date)) == "Sunday" | weekdays(as.Date(data$date)) == "Saturday"
partOfWeek <- ifelse(partOfWeek==TRUE, "Weekend", "Weekday")
partOfWeek <- as.factor(partOfWeek)
dataComplete <- cbind(dataComplete, partOfWeek);
partOfWeek <- weekdays(as.Date(dataComplete$date)) == "Sunday" | weekdays(as.Date(dataComplete$date)) == "Saturday"
partOfWeek <- ifelse(partOfWeek==TRUE, "Weekend", "Weekday")
partOfWeek <- as.factor(partOfWeek)
dataComplete <- cbind(dataComplete, partOfWeek);
View(dataComplete)
stepInterval <- sqldf("select interval, part_of_week, sum(steps) as steps, count(steps) as count from dataComplete group by interval,part_of_week");
View(dataComplete)
stepInterval <- sqldf("select interval, partOfWeek, sum(steps) as steps, count(steps) as count from dataComplete group by interval,part_of_week");
stepInterval <- sqldf("select interval, partOfWeek, sum(steps) as steps, count(steps) as count from dataComplete group by interval, partOfWeek");
average <- stepInterval$steps / stepInterval$count;
stepInterval <- cbind( stepInterval, average );
ggplot(stepInterval, aes(interval, average)) + geom_line() + xlab("Interval") + ylab("Mean steps") + ggtitle("Average Daily Activity") + facet_grid(facets=partOfWeek ~ .)
ggplot(stepInterval, aes(interval, average)) + geom_line() + xlab("Interval") + ylab("Mean steps") + ggtitle("Average Daily Activity Grouped by Weekday and Weekend") + facet_grid(facets=partOfWeek ~ .)
